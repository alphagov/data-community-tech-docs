---
title: Access the publishing database
weight: 39
last_reviewed_on: 2021-11-04
review_in: 6 months
---

# Access the GOV.UK publishing database

The GOV.UK publishing database is a PostgreSQL database that keeps a copy of every version of every page published on GOV.UK.

You can connect to and access the publishing database instead of [downloading the GOV.UK mirror to your local machine](/analysis/mirror/). You can use the publishing database to compute intents.

The data community does not currently have access to the production environment of the publishing database, so we access the database using the integration environment.

Instead of connecting to the integration environment database, you can download a backup of the publishing database to your local machine if you need to:

- run resource-intensive queries on the database, as these queries may affect live services that also use the database
- create your own tables within the database, as you only have read access to the integration environment database

## Connect to the publishing database

Before you start, you must:

- have access to AWS
- install the GDS command line tools
- connect to the GDS VPN
- get Secure Shell (SSH) access to the integration environment

See the [Get started on GOV.UK developer documentation](https://docs.publishing.service.gov.uk/manual/get-started.html) for more information on how to do this.

1. Run the following in the command line to connect to an AWS instance in the integration environment:

    ```
    USER=<FIRSTNAMELASTNAME>; gds govuk connect --environment integration ssh publishing_api_db_admin
    ```

    `<FIRSTNAMELASTNAME>` must be the same user that you created to SSH into integration.

    You do not need to include `USER=<FIRSTNAMELASTNAME>;` if your username for your machine is the same as the SSH integration user.

1. Open a PostgreSQL terminal to the `postgresql-primary` host as the `aws_db_admin` user, and connect to the publishing API database:

    ```
    sudo psql -U aws_db_admin -h publishing-api-postgres --no-password -d publishing_api_production
    ```

    This database is named `production`, but it is not in the production environment.

### Download query results

One way is to print the results of the query at the command line, and redirect
it to a local file.  Another is to write the results to a file in the `db_admin`
server, compress it, and then download it to your device.

#### Print at the command line

```
USER=<FIRSTNAMELASTNAME>; gds govuk connect --environment integration ssh db_admin sudo "psql -U aws_db_admin -h postgresql-primary --no-password -d publishing_api_production -c \"<SQL-QUERY>\"" > <FILENAME>
```

where:
- `<SQL-QUERY>` is a SQL query
- `<FILENAME>` is the name of a file to write the query results to.

#### Write to a file in the server

The `gds govuk connect` command provides `scp-pull` to fetch a file from a server and save it locally.  This enables the following workflow.

1. Execute the query, and save the results to a file in the `db_admin` server.  Note that the `db_admin` server doesn't run the database itself.

    ```
    USER=<FIRSTNAMELASTNAME>; gds govuk connect --environment integration ssh db_admin:1 sudo "psql -U aws_db_admin -h postgresql-primary --no-password -d publishing_api_production -c \"\\copy ($(<<QUERY-FILE>)) TO '/tmp/<FILENAME>.csv' WITH CSV HEADER\""
    ```
    where:
    - `<QUERY-FILE>` is a file on your device that contains an SQL query.  Note that the first `<` symbol in `<<QUERY-FILE>` should remain, for example `<myfile.sql`.
    - `<FILENAME>` will be a file in the server that contains the query results.

1. Compress the results file.

    ```
    gds govuk connect --environment integration ssh db_admin zip "/tmp/<FILENAME>.zip /tmp/<FILENAME>.csv"
    ```
    where `<FILENAME>` is the same as in the previous step.

1. Use scp-pull to fetch the file locally to your laptop.

    ```
    gds govuk connect --environment integration scp-pull db_admin:1 /tmp/<FILENAME>.zip <DOWNLOAD-LOCATION>
    ```
    where:
    - `<FILENAME>` is the same as in the previous step.
    - `<DOWNLOAD-LOCATION>` is the location you want to download the backup file to on your local machine

The `:1` in `db_admin:1` guarantees that `scp-pull` will connect to the same machine as `ssh`.  The `1` chooses the first available machine (in lexicographical order of something, maybe the IP address), and in integration there is only one machine anyway, so `1` is guaranteed to exist.

### Upload the downloaded results into BigQuery

The quickest way to upload a CSV file into BigQuery is to first convert it into
a Parquet file.  This can be done in Python with the Pandas package, which can
read the CSV file directly from a zip file.

```
import pandas as pd
df = pd.read_csv("<FILENAME>.zip")

# gzip compression is slower than snappy (default) but creates a much smaller file (123MB rather than 302MB)
df.to_parquet("<FILENAME>.parquet", compression='gzip')
```
where `<FILENAME>` is the name of the zipped CSV file and of the Parquet file that
you want to convert it into.

The Parquet file can then be uploaded to BigQuery using the Google Cloud SDK
command `bq` at the command line.

```
bq load --source_format=PARQUET <DATASET>.<TABLE> <FILENAME>.parquet
```
where:
- `<FILENAME>` is the same as in the previous step
- `<DATASET>` and `<TABLE>` are where to put the data in BigQuery.

## Download a backup of the publishing database

Instead of connecting to the integration environment database, you can download a backup of the publishing database to your local machine if you need to:

- run resource-intensive queries on the database, as these queries may affect live services that also use the database
- create your own tables within the database, as you only have read access to the integration environment database

Before you start, you must:

- have [access to AWS](https://docs.publishing.service.gov.uk/manual/get-started.html#7-get-aws-access)
- install the [GDS command line tools](https://docs.publishing.service.gov.uk/manual/get-started.html#3-install-gds-command-line-tools)

You do not need the GDS VPN or Secure Shell (SSH) access to the integration environment.

### Download the database backup

1. The filename of the latest database backup in AWS S3 varies, depending on the date and time the backup was created. Run the following command to find out the filename:

    ```sh
    gds aws govuk-integration-readonly aws s3 ls s3://govuk-integration-database-backups/publishing-api-postgres/
    ```

1. Download the backup of the publishing API database:

    ```sh
    gds aws govuk-integration-readonly aws s3 cp s3://govuk-integration-database-backups/publishing-api-postgres/<FILENAME> <DOWNLOAD-LOCATION>
    ```
    where:
    - `<YYYY-MM-DD>T<HH:MM:SS>` is the filename of the backup database
    - `<DOWNLOAD-LOCATION>` is the location you want to download the backup file to on your local machine

### Open the database on your local machine

To work with the database backup on your local machine, you must open the backup on a database system.

The following content assumes you’re using [PostgreSQL](https://www.postgresql.org/) as your database system.

1. Run the following command to create a PostgreSQL database user called `publishing_api`:

    ```sh
    sudo -u postgres createuser -s publishing_api
    ```
1. Load the data from the backup database into a new PostgreSQL database called `publishing_api_production`:

    ```sh
    pg_restore --verbose --create --jobs=4 --dbname=postgres <DOWNLOAD-LOCATION>
    ```
    where:
    - `--jobs=4` is the number of CPU threads that will be used.  You can change this to suit your device.
    - `<DOWNLOAD-LOCATION>` is the location that you downloaded the backup file to on your local machine.

When your command line becomes responsive and you can enter commands again, this means you’ll have successfully created a database named `publishing_api_production` that contains the publishing API backup data.

### Run queries in the database

1. Run the following command to start using the database.

    ```sh
    psql -d publishing_api_production
    ```

    You should see the following output:

    ```text
    psql (13.6)
    Type "help" for help.

    publishing_api_production=#
    ```

1. Enter a query to start using the database. For example:

    ```sql
    SELECT title FROM editions LIMIT 5;
    ```

You can now work with this database in PostgreSQL. To learn more about using PostgreSQL, [read the PostgreSQL documentation](https://www.postgresql.org/docs/).
