---
title: Use the spider diagram tool
weight: 39.3
last_reviewed_on: 2022-02-23
review_in: 6 months
---

# Use the spider diagram tool

The spider diagram tool is a visualisation tool that shows the page users come from before going to a page of interest, and which page do the users go to after the page of interest.

This data is over a date range, and is broken down by device category, internal/external links, and the individual entry/exit pages paired with the count and proportion of page views.

To use the spider diagram tool, you must do the following.

1. Download the spider diagram tool notebook.
1. Open the tool notebook in Google Colab.
1. Run the notebook.

## Download the spider diagram tool

___Do you need any specific permission to do this?___

Download the notebook from GitHub.

1. Go to the [`govuk-user-journey-analysis-tools` GitHub repo][repository].
1. Select the __Code__ button, and then select __Download Zip__.
1. Unzip the __govuk-user-journey-analysis-tools__ folder and go to the __notebooks__ folder.
1. Save the __spider-diagram-tool__ Jupyter notebook to your Google Drive account.

## Open the tool notebook in Google Colab

1. Go to [Google Colab](https://colab.research.google.com/). You will see an window to open a notebook.
1. Select the __Google Drive__ tab and open the __spider-diagram-tool__ notebook.

___Cannot find below___

You may need to 'connect' the notebook to be associated with Google Colab the first time you open a Jupyter
notebook from Google Drive. To do this, look for the link at the top-centre of the page which says something
like `Connect more apps` (see screenshot below), search for `Google Colaboratory` and then accept any required
permissions it asks for. Once you have associated Jupyter notebooks with Google Colab, the notebook should open.

## Run the tool notebook

To run the notebook, you must do the following.

1. Authenticate your access.
1. Set the input variables.
1. Run the query cells.
1. Run the __Execute queries__ cell.
1. Create the visualisation.

### Authenticate your access

1. Hover your cursor over the cell that starts with the code `from datetime import datetime` to show the run icon. Select the run icon to start the authentication process.
1. Select the authentication link in the text box and then select your Google account.
1. Follow the on screen prompts, selecting __Allow__ when prompted, and copy the __Sign in code__ when this code appears.
1. Go back to the text box in the notebook and paste the sign in code into the __Enter verification code__ field.
1. Select __Enter__ to complete authentication.

If you receive a warning message saying "The notebook was not authored by Google", select __Run Anyway__.

### Set the input variables

You must complete and run the 3 cells in the __Input Variables__ ___cell category???___.

1. Complete the __Set Input Variables Form__ by entering the following fields:
  - `project_id` - the GOV.UK page of interest you want to visualise entries and exits for
  - `ga_dataset` - ___??? do you need to set this?___
  - `start_date` and `end_date` - the date range you want to look at, in `YYYY/MM/DD` format
  - `page_path` - ___??? how does this relate to the following one?___
  - `path_or_title` - ___??? can you select both? how does it relate to the previous one?___
  - `remove_query_string` - ___???___
  - device categories - you must select at least one device type from __Desktop__, __Mobile__ or __Tablet__, otherwise the code will not run and will raise a `ValueError`

  ___which are mandatory and which are optional? are there any that must always be ticked?___

1. Run the other 2 cells in the __Input Variables__ ___cell category???___.

### Run the query cells

Run the following cells in the following order.

1. __Query -- Previous Page Path__.
1. __Query -- Acquisition Source__.
1. __Query -- Next Page Path__.

### Run the __Execute queries__ cell

The __Execute queries__ cell estimates the number of gigabytes read by the query and shows you the amount.

If you are happy to run the query, enter "yes" into the user input box.

If you leave the input box blank or type in something other than "yes", the query will not run.

### Create the visualisation

1. Run the __Compile summary statistics__ cell.

1. Run the 3 __Create plotly figure__ cells to generate an interactive plotly figure visualisation onscreen.

  To download the plot as a .png, hover your cursor over the figure and select the camera icon located in the top right-hand menu.

## Save a local copy of the data

To download a local copy of the data generated for the Spider Diagram tool, run the __Export data, and figure__ cell.

Running this cell downloads the following files to your local machine:

- a CSV file of the entry and exit data, including the number and proportion of page views
- an HTML file of the plotly figure
- a text file of the metadata for the executed SQL queries

If none or only some of the files are downloaded, check the end of the URL search bar. If you see a download icon with a red cross, select the icon and change the option to __Always allow....__, and then select __Done__.

[assumptions]: ../aqa/assumptions-caveats-spider-diagram-tool.md
[repository]: https://github.com/alphagov/govuk-user-journey-analysis-tools

## Assumptions and caveats

This log contains a list of assumptions and caveats used in the Forward Path tool analysis.

### Definitions

Assumptions are RAG-rated according to the following definitions for quality and impact.

| RAG   | Assumption quality | Assumption impact |
|---|---|---|
|Green|Reliable assumption, well understood and/or documented; anything up to a validated & recent set of actual data.|Marginal assumptions; their changes have no or limited impact on the outputs.|
|Amber|Some evidence to support the assumption; may vary from a source with poor methodology to a good source that is a few years old.|Assumptions with a relevant, even if not critical, impact on the outputs.|
|Red|Little evidence to support the assumption; may vary from an opinion to a limited data source with poor methodology|Core assumptions of the analysis; the output would be drastically affected by their change.|

Thank you to the Home Office Analytical Quality Assurance team for these definitions.

# Assumption 1: Prioritise visualisation by aggregating all pages that have less than 2.5% of sessions to `(other)`

* Quality: Green (for visualisation purposes)
* Impact: Green (for visualisation purposes)

Pages that contain less than 2.5% of overall sessions are difficult to see in the diagram both in terms of their volume, and any associated labels.

To mitigate this, all pages with less than 2.5% of overall sessions are aggregated into a separate category, `(other)`. This happens immediately after the tool has executed the SQL queries, but before the tool has rendered the visualisations and outputs.

As this is strictly for visualisation purposes, it is acceptable. However, any downstream analysis of the outputs is obviously limited due to this aggregation. As such, outputs of this tool should not be used for further quantitative analysis without a thorough understanding of this assumption's implications.

### Assumption 2: URL query parameters and anchors are excluded from page paths

* Quality: Green
* Impact: Green

All URL query parameters and anchors have been removed from page paths so that page views are associated with the
general page path URL, rather than specific query parameters and anchors. The URL parameters and anchors are removed
during SQL execution.

The URL parameters and anchors are removed as the overall aim of the tool is to provide an understanding of which page paths have been viewed, regardless of query parameters and anchors. This is in line with Google Analytics, which also excludes query parameters and anchors from the page path.
