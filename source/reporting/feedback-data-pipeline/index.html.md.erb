---
title: Feedback data processing pipeline
weight: 41
last_reviewed_on: 2022-02-14
review_in: 6 months
---

# Feedback data processing pipeline

GOV.UK users can provide feedback about GOV.UK by selecting the:

- __Is this page useful? Yes or No__ button on a GOV.UK page to provide qualitative feedback about their experience on GOV.UK
- __Report a problem__ button on a GOV.UK page to report issues with that page
- __Contact__ link in a GOV.UK page footer to go to a service-specific contact page to leave written feedback

These feedback methods appear on all GOV.UK pages.

The Data Insights team collects and organises feedback data from multiple sources to make that data available to GDS users for analysis.

The feedback data processing pipeline has 3 stages:

- read the feedback data into the pipeline from the data sources
- process the feedback data to make it ready for analysis
- analyse the feedback data

The following content explains how each stage of this pipeline works.

## Read the feedback data into the pipeline

Feedback data is stored in one of the following data sources, depending on how users submitted feedback:

- [SmartSurvey](https://www.smartsurvey.co.uk/) stores the __Is this page useful?__ survey results
- the [Support API](https://github.com/alphagov/support-api) stores both the ‘Report a problem’ issue descriptions and ‘Contact’ request details

Every day, the pipeline reads the previous day's data from the 2 data sources and stores that data in the [Google Cloud Platform](https://cloud.google.com/) as a raw text file.

The pipeline does not do any processing or transformation of data at this stage.

## Process the feedback data

The pipeline processes the feedback data from the 2 data sources to make it ready for analysis.

The data processing is the same regardless of the data source, and consists of several steps.

### Read the data into the pipeline

The pipeline reads the raw text data file from the Google Cloud Platform into the pipeline programming environment in Python.

### Structure the data

The data from SmartSurvey and the Support API are structured differently, but share characteristics such as prompt-response pairs and metadata about the feedback.

The pipeline changes the format of the data from both data sources to be consistent with one another and to adhere to the required output data format.

### Remove whitespace from the data

Pruning is a data cleansing method that removes nonsensical or irrelevant feedback text from a feedback data record.

Examples of pruning include trimming whitespace and removing URL parameters or code snippets.

In this step, the pipeline prunes whitespace from the beginning and end of the feedback data text.

The pipeline also searches for multiple consecutive whitespaces in feedback data text and reduces those to one space if it finds any.

### Remove profanity from the data

Masking replaces a portion of feedback text with a text mask indicating the feedback text has been modified.

An example of a text mask is `****`.

In this step, the pipeline finds and replaces any profane words in the feedback text with the mask pattern of `****`.

### Remove Personally Identifiable Information (PII) from the data

The pipeline sends the feedback data to the [Google Cloud Data Loss Prevention (DLP)](https://cloud.google.com/dlp) service.

Google Cloud DLP looks for the following information types:

```
info_types = [
    'DATE_OF_BIRTH',
    'EMAIL_ADDRESS',
    'PASSPORT',
    'PERSON_NAME',
    'PHONE_NUMBER',
    'STREET_ADDRESS',
    'UK_NATIONAL_INSURANCE_NUMBER',
    'UK_PASSPORT',
    'CREDIT_CARD_NUMBER',
    'IBAN_CODE',
    'IP_ADDRESS',
    'MEDICAL_TERM',
    'VEHICLE_IDENTIFICATION_NUMBER',
    'SCOTLAND_COMMUNITY_HEALTH_INDEX_NUMBER',
    'UK_DRIVERS_LICENSE_NUMBER',
    'UK_NATIONAL_HEALTH_SERVICE_NUMBER',
    'UK_TAXPAYER_REFERENCE',
    'SWIFT_CODE'
]
```

Google Cloud DLP then masks any instances of feedback data text that matches these information types and returns the cleansed data to the pipeline.

### Nest the data values and group the data

A single feedback record may contain multiple prompt-response pairs. For example, a single record may have the following pairs:

- "What was the problem?" "The link to the PDF did not work"
- "Were there any other issues?" "No"

In the feedback data set, every prompt-response pair would have a feedback record with metadata about the record. For example:

|Date|Time|URL|Prompt|Response|
|:---|:---|:---|:---|:---|
|2022-07-27|12:34:56|https://www.gov.uk/examplefeedback.html|What was the problem?|The link to the PDF did not work|
|2022-07-27|12:34:56|https://www.gov.uk/examplefeedback.html|Were there any other issues?|No|

This means there is a lot of duplication in the feedback data set.

In this step, the pipeline nests the data values and groups the data to remove the feedback record metadata duplication.

Now there is one feedback record for the multiple prompt-response pairs that relate to that feedback record. For example:

|Date|Time|URL|Prompt|Response|
|:---|:---|:---|:---|:---|
|2022-07-27|12:34:56|https://www.gov.uk/examplefeedback.html|What was the problem?|The link to the PDF did not work|
||||Were there any other issues?|No|

The pipeline has finished processing the data.

### Save the processed feedback data

The pipeline saves the processed data into the `govuk_user_feedback` table in the `govuk-bigquery-analytics` BigQuery project.

To request permission to view or edit these data tables in BigQuery, speak to the GDS Data Products team on the [#govuk-data-labs Slack channel](https://app.slack.com/client/T8GT9416G/CHR4UQKU4).

The Support API and SmartSurvey feedback data is now ready for users to view and analyse in BigQuery.

## Analyse the feedback data

The feedback pipeline cleans and analyses the processed feedback data from BigQuery on a monthly basis.

The pipeline reads processed feedback data for the previous month where that feedback data contains a free-form text input.

The feedback pipeline then sends this data to a Python pipeline. The Python pipeline then performs 2 separate analysis processes:

- the first analysis process is at a sentence level, and identifies what the feedback is about and what the user feedback sentiment is
- the second analysis process is at a feedback record level, and identifies and groups feedback records by topic

The Python pipeline then sends the output data to BigQuery and the Data Insights team includes it in the monthly insights report.

### Format the data

The Python pipeline:

- transforms all feedback record text to lowercase
- removes all positive and negative contractions from the feedback record text

### Sentence level analysis

The Python pipeline runs the sentence-level analysis process.

This process:

- cleanses the sentence-level data
- identifies the user feedback sentiment, that is whether the feedback is positive, negative or neutral
- clusters the feedback records based on subject matter

#### Cleansing the sentence-level data

1. The Python pipeline formats the data so that every sentence in the data has a corresponding feedback record. For example:

    |Feedback record number|Feedback|
    |:---|:---|
    |1|I like this feature. It is good. It makes me happy. I will recommend it to others.|
    |2|I hate this feature. It is bad.|

    This step changes this data format to the following:

    |Feedback record number|Feedback sentence|
    |:---|:---|
    |1|I like this feature.|
    |1|It is good.|
    |1|It makes me happy.|
    |1|I will recommend it to others.|
    |2|I hate this feature.|
    |2|It is bad.|

1. The Python pipeline re-removes any whitespace from the feedback record text that the previous steps inadvertently added.

1. Finally, the Python pipeline removes all line breaks from feedback text.

The output from the process is feedback record text that is all alphanumeric, with no punctuation or whitespace, and is in a single block.

#### Identifying the user feedback sentiment

The pipeline uses the following 3 pre-trained language models that classify feedback record text as positive, negative or neutral:

- [BERT analyse](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)
- [SieBERT](https://huggingface.co/siebert/sentiment-roberta-large-english)
- [Cardiff](https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment)

This classification is also known as user sentiment.

The 3 models each add a sentiment column to the feedback record, and then the pipeline derives an overall sentiment based on these 3 outputs.

#### Clustering the feedback records based on subject matter

To identify what the feedback records are about and cluster them accordingly, the Python pipeline does the following data cleansing:

1. The Python pipeline removes the stop words.

    Stop words are words which are classified as insignificant and filtered out of natural language data processing.

    Examples of stop words are 'and' and 'to'.

1. The Python pipeline removes all punctuation from the feedback record text, leaving only alphanumeric characters (a-z and 0-9).

1. The Python pipeline runs the [GSDMM Analyse algorithm](https://github.com/rwalk/gsdmm) to cluster similar feedback records based on the text within those records.

The feedback records now:

- are clustered at a sentence level
- have a sentiment value attached to them

### Feedback record-level analysis

The pipeline runs the feedback record-level analysis process.

1. The pipeline removes the following from the text:
    - punctuation
    - whitespace
    - line breaks

1. The pipeline runs the [BERT analyse language model](https://github.com/MaartenGr/BERTopic) to identify themes in the feedback records.

    The pipeline attaches a topic number to the feedback record, and also outputs the top 10 feedback records associated with each topic.

1. Finally, the pipeline removes stop words from the feedback records.

## Feedback data processing pipeline outputs

You can view the outputs from the feedback data processing pipeline in the monthly data insights report.

To access this report, contact either the [Data Insights](https://gds.slack.com/archives/C015XA8KC4F) or [Data Services](https://gds.slack.com/archives/C03CLQJH94Z) teams on Slack.

## Data field definitions

All data fields in BigQuery are text strings.

For more information on the BigQuery data field definitions, see the [Google Analytics BigQuery Export schema documentation](https://support.google.com/analytics/answer/3437719).

## Supporting information

See the [`govuk-feedback-pipeline` repo on GitHub](https://github.com/alphagov/govuk-feedback-pipeline) for more information.
